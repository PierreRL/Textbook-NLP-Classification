{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification of Textbooks\n",
    "### Pierre Lardet\n",
    "\n",
    "This code is presented as a python notebook, using python 3.11.2. My thoughts are presented chronologically\n",
    "\n",
    "Versions of libraries used are listed below.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning\n",
    "\n",
    "Before anything else, we need to be able to read in the text and convert it into a format which is easy to manipulate. I'm going to use a [Pandas dataframe](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html). I noticed that the Computer Science text files were nested in an extra directory so manually moved them to make the structure of text files consistent. Next, I read in all of the text files in an easily extensible manner, stored them in a 2d array labelled with their subject and created a new Pandas dataframe to make further manipulation easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "subjects = ['Computer_Science', 'History', 'Maths']\n",
    "raw_texts = []\n",
    "\n",
    "def read_subject_data(subject:str)->None:\n",
    "    for dir in glob.glob(f'./data/{subject}/*.txt'):\n",
    "        f = open(dir, 'r')\n",
    "        text = f.read()\n",
    "        raw_texts.append([subject, text, dir])\n",
    "        f.close()\n",
    "\n",
    "for subject in subjects:\n",
    "    read_subject_data(subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Sample of the data: \n",
      "             subject                                               text\n",
      "0  Computer_Science  4.8 Exercises 275\\n4.15 [IS) <§§4.2, 4.3> One ...\n",
      "1  Computer_Science  4.5 Fallacies and Pitfalls 26.\\nFirst we find ...\n",
      "2  Computer_Science  518 Chapter 7 Large and Fast: Exploiting Memor...\n",
      "3  Computer_Science  Computers\\nReconstructing the\\nin the\\nAncient...\n",
      "4  Computer_Science  230 Chapter 3 Arithmetic: for Computers\\n3.9 [...\n",
      "--------------------------------------------------\n",
      "Dimensions: (1356, 2)\n",
      "--------------------------------------------------\n",
      "Counts of each subject: \n",
      "                   text\n",
      "subject               \n",
      "Computer_Science   642\n",
      "History            500\n",
      "Maths              214\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "textbooks = pd.DataFrame(raw_texts, columns=['subject', 'text' ,'dir'])\n",
    "\n",
    "print('-'*50)\n",
    "print(f'Sample of the data: \\n {textbooks.head()}')\n",
    "print('-'*50)\n",
    "print(f'Dimensions: {textbooks.shape}')\n",
    "print('-'*50)\n",
    "print(f'Counts of each subject: \\n {textbooks.groupby(\"subject\").count()}')\n",
    "print('-'*50)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a dataframe to work with. The text is currently very messy with lots of extra characters and spacing etc. In order to use the text as an input into a ML classification model, it needs to be much cleaner. The desired format will be a list of lower-case words in each sample which can later be converted to numeric values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            subject                                               text\n",
      "0  Computer_Science  4 8 Exercises 275 4 15 IS 4 2 4 3 One user has...\n",
      "1  Computer_Science  4 5 Fallacies and Pitfalls 26 First we find th...\n",
      "2  Computer_Science  518 Chapter 7 Large and Fast Exploiting Memory...\n",
      "3  Computer_Science  Computers Reconstructing the in the Ancient Wo...\n",
      "4  Computer_Science  230 Chapter 3 Arithmetic for Computers 3 9 IOJ...\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(str:str)->str:\n",
    "    str = re.sub(r'\\n', ' ', str)\n",
    "    str = re.sub(r'\\W+', ' ', str)\n",
    "    return str\n",
    "\n",
    "textbooks['text'] = textbooks['text'].apply(clean_text)\n",
    "\n",
    "print(textbooks.head())\n",
    "textbooks.dropna(how='any',inplace=True)\n",
    "textbooks.to_csv('output.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
